group.id=AI Chat Notification Group
group.ActionGroup2.text=AI Chat

action.ask=Ask AI...
action.ask.desc=Run Custom Prompt or Add Custom Action
action.code.optimize.menu=Optimize
action.code.test.menu=Add Test Case
action.code.wrong.menu=Find Bug
action.code.explain.menu=Explain
action.code.custom.action=Custom AI Chat Actions
action.code.minimize.menu=Minimize
action.refresh=Reset Thread
action.settings=Settings

apiKey.missing=Your API Key, find it on: {0}

code.fragment.title=Selected code from {0}
editor.diff.action.name=Compare with Editor
editor.diff.action.desc=Compare with Editor
editor.diff.local.content.title=AI suggested code
editor.diff.title=AI Diff
editor.diff.w/sel.action.name=Compare with Selection
editor.diff.w/sel.action.desc=Compare with Selection

notify.config.title=Missing setting
notify.config.apikey.text=Please configure an API key first.
notify.config.opts.text=Please configure first the following: {0}.
notify.config.action.config=Configure
notify.config.action.browse=Create new API key
notify.config.action.browse.url=https://platform.openai.com/account/api-keys

toolwindow.stripe.com.didalgo.ChatGPT=AI Chat

ui.attachedImage=Attached image
ui.attachedImages=Attached images ({0})
ui.toolwindow.send=Send
ui.setting.menu.text=AI Chat
ui.setting.connection.title=Connection Settings
ui.setting.connection.read_timeout.label=Read Timeout (ms):
ui.setting.connection.read_timeout.remark=Time for reading data from the server
ui.setting.connection.read_timeout.empty_text=10 seconds by default
ui.setting.temperature.tooltip=A sampling temperature used, between. Higher values like 1.0 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.
ui.setting.topp.tooltip=Controls the randomness of the text generation by nucleus sampling. The model only considers a subset of tokens whose cumulative probability mass adds up to a certain threshold (top_p).
popup.title.paste.target=Choose Paste Target
image.n=Image {0}
image.pasted.name=Pasted Image {0}
llm.test.btn=Test Connection
llm.test.msg=Say: hello
llm.test.out=Connection successful\nModel says: {0}
model.list.refresh=Refresh Models
model.list.reset=Reset Models
usage.in.out=Tokens: <strong>{0} \u2192 {1}</strong>
usage.in.out.max=Tokens: <strong>{0} \u2192 {1} / {2}</strong>
enable.stream.options=Enable `stream_options`
